{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA  Submission\n",
    "\n",
    "\n",
    "\n",
    "**Your Name:** Larry Tientcheu\n",
    "\n",
    "## Algorithm Description \n",
    "\n",
    "### 1. General Information\n",
    "\n",
    "**Intended Use Statement:** \n",
    "\n",
    "* Assist the radiologist in the early diagnosis of Pneumonia from chest X-ray images of a patient to prevent adverse consequences (including death).\n",
    "\n",
    "**Indications for Use:**\n",
    "\n",
    "* Looking at the data in our EDA, we see that the algorithm was trained on patients who spanned from ages 0 to 90.\n",
    "* Algorithm should be used for screening chest X-rays studies on patients from ages 0 to 90.\n",
    "\n",
    "**Device Limitations:**\n",
    "\n",
    "* The first biggest limitation is that there is no history of the associated patient considered in our evaluation model. \n",
    "* Since the model exercises a lot of convolutional layers, it needs very high computational power otherwise it’ll eat up a lot of time in computations.\n",
    "\n",
    "**Clinical Impact of Performance:**\n",
    "\n",
    "* All medical tests can result in false positive and false negative errors. Since medical tests can’t be absolutely true, false positives and false negatives are two problems we have to deal with. A false positive can lead to unnecessary treatment and a false negative can lead to a false diagnostic, which is very serious since a disease has been ignored. However, we can minimize the errors by collecting more information, considering other variables, adjusting the sensitivity (true positive rate) and specificity (true negative rate) of the test, or conducting the test multiple times. Even so, it is still hard since reducing one type of error means increasing the other type of error.\n",
    "* For the clinical relevance, we have chosen sensitivity. Since our algorithm is used for screening studies, it is most confident when the test is negative, does eliminating most of the negative cases, enabling the radiologist to focus more on positive cases.\n",
    "* **Recall Value: 0.571429**\n",
    "* **Precision is: 0.307692**\n",
    "* **Recall is: 0.5**\n",
    "* **Threshold is: 0.442853**\n",
    "* **F1 Score is:0.400000**\n",
    "\n",
    "### 2. Algorithm Design and Function\n",
    "\n",
    "![alt text](flowchart.png \"Algorithm Folwchart\")\n",
    "\n",
    "**DICOM Checking Steps:**\n",
    "\n",
    "* Validation set consist of Chest X-ray images from patients ages 0 to 90.\n",
    "\n",
    "* Patient ID: Unique identifier of the sample. It is the link between the x-ray images and the annotations for each of the samples.\n",
    "\n",
    "* Radiographic image: Image with fixed dimensions of 1024 x 1024.\n",
    "\n",
    "* Sex of the patient: Categorical variable.\n",
    "\n",
    "* Patient’s age: Numerical variable.\n",
    "\n",
    "* View: Provides information on how the x-ray was taken. In PA view the x-ray passes from posterior of body to anterior and vice versa in the case of the AP view. Preferably the PA view is used, but for very sick people who cannot maintain their upright position the AP view is used\n",
    "\n",
    "* Before sending the image through the algorithm, the image position, image type and body part were checked. Images that are not from the chest, not taken from either PA or AP positions and Modality not DX were excluded.\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "\n",
    "* All images were normalized and the training set was augmented using horizontal flip and 10 degree range rotation.\n",
    "* Training set ad Validation set both have appropriate proportions of posititve and negative cases. with a 80 to 20 split\n",
    "* Target: It reduces the previous categorization in Binary x-ray cathegory where 0 means that the image is not a case of pneumonia and 1 if it is a case of pneumonia.\n",
    "\n",
    "**CNN Architecture:**\n",
    "\n",
    "```\n",
    "\n",
    "Model: \"vgg16\"\n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "\n",
    "=================================================================\n",
    "\n",
    "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "flatten (Flatten)            (None, 25088)             0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "fc1 (Dense)                  (None, 4096)              102764544 \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "fc2 (Dense)                  (None, 4096)              16781312  \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "predictions (Dense)          (None, 1000)              4097000   \n",
    "\n",
    "=================================================================\n",
    "\n",
    "Total params: 138,357,544\n",
    "\n",
    "Trainable params: 138,357,544\n",
    "\n",
    "Non-trainable params: 0\n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "Model: \"sequential_3\"\n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "\n",
    "=================================================================\n",
    "\n",
    "model_3 (Model)              (None, 7, 7, 512)         14714688  \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "flatten_3 (Flatten)          (None, 25088)             0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "dropout_7 (Dropout)          (None, 25088)             0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "dense_9 (Dense)              (None, 512)               12845568  \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "dropout_8 (Dropout)          (None, 512)               0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "dense_10 (Dense)             (None, 256)               131328    \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "dropout_9 (Dropout)          (None, 256)               0         \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "dense_11 (Dense)             (None, 64)                16448     \n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "dense_12 (Dense)             (None, 1)                 65        \n",
    "\n",
    "=================================================================\n",
    "\n",
    "Total params: 27,708,097\n",
    "\n",
    "Trainable params: 15,353,217\n",
    "\n",
    "Non-trainable params: 12,354,880\n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "```\n",
    "\n",
    "### 3. Algorithm Training\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "* Types of augmentation used during training: `ImageDataGenerator(rescale=1. / 255.0,horizontal_flip = True,vertical_flip = False,height_shift_range= 0.1, width_shift_range=0.1,rotation_range=10,shear_range = 0.1,zoom_range=0.1)`\n",
    "\n",
    "* Batch size : `Training set = 32`, `Validation set = 32`\n",
    "\n",
    "* Optimizer learning rate = Adam(lr=0.001)\n",
    "\n",
    "* Layers of pre-existing architecture that were frozen: 17\n",
    "\n",
    "* Layers of pre-existing architecture that were fine-tuned: 0\n",
    "\n",
    "* Layers added to pre-existing architecture: 4\n",
    "\n",
    "\n",
    "##### Training Loss Curve\n",
    "\n",
    "![alt text](training_loss.png \"Loss Curve\")\n",
    "\n",
    "\n",
    "\n",
    "##### Precison Recall Curve\n",
    "\n",
    "![alt text](pr_curve.png \"Precision Recall Curve\")\n",
    "\n",
    "\n",
    "\n",
    "* A high precision test gives you more confidence that a positive test result is actually positive since a high precision test has low false positive. This metric, however, does not take false negatives into account. So a high precision test could still miss a lot of positive cases. Because of this, high-precision tests don’t necessarily make for great stand-alone diagnostics but are beneficial when you want to confirm a suspected diagnosis.\n",
    "\n",
    "\n",
    "\n",
    "* When a high recall test returns a negative result, you can be confident that the result is truly negative since a high recall test has low false negatives. Recall does not take false positives into account though, so you may have high recall but are still labeling a lot of negative cases as positive. Because of this, high recall tests are good for things like screening studies, where you want to make sure someone doesn’t have a disease or worklist prioritization where you want to make sure that people without the disease are being de-prioritized.\n",
    "\n",
    "\n",
    "\n",
    "* Optimizing one of these metrics usually comes at the expense of sacrificing the other. \n",
    "\n",
    "\n",
    "\n",
    "#### F1 vs Threshold graph\n",
    "\n",
    "![alt text](f1_thresh.png \"F! vs Threshold Graph\")\n",
    "\n",
    "\n",
    "\n",
    "**Final Threshold and Explanation:**\n",
    "\n",
    "\n",
    "\n",
    "* We have chosen a threshold according to our F1 score. The threshold is determined by taking the highest F1 score obtained on sensitivity(recall). Since our algorithm is used for screening studies, it is most confident when the test is negative, thus, eliminating most of the negative cases, enabling the radiologist to focus more on positive cases. `F1 = 0.352941` ,`Threshold = 0.559925`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 4. Databases\n",
    "\n",
    "\n",
    "\n",
    "**Description of Training Dataset:** \n",
    "\n",
    "\n",
    "\n",
    "* The training dataset consists of patients varying from age 0 to 90, both Male and Female. It contains a combination of images with Pneumonia and some of it comorbities and images with No Findings. The training set has been slpit 50% Pneumonia and the other 50% No Fidings.\n",
    "\n",
    "\n",
    "\n",
    "![alt text](td_sample.png \"Training Data\")\n",
    "\n",
    "\n",
    "\n",
    "**Description of Validation Dataset:** \n",
    "\n",
    "\n",
    "\n",
    "* The validation dataset consists of patients varying from age 0 to 90, both Male and Female. It contains a combination of images with Pneumonia and some of it comorbities and images with No Findings. The validation set has been made imbalanced with more No Findings than Pneumonia in order to relfect the real life scenarios.\n",
    "\n",
    "![alt text](vd_sample.png \"Validation Data Samples\")\n",
    "\n",
    "### 5. Ground Truth\n",
    "\n",
    "\n",
    "\n",
    "* Ground truth of the NIH dataset ground truth is derived from the labels labels in the NIH dataset. This could be a good thing because we believe a radiologist labeled these images. However, Since the NLP-derived labels from the NIH are sub-optimal, This could impact the algorithm’s clinical performance.\n",
    "\n",
    "\n",
    "\n",
    "### 6. FDA Validation Plan\n",
    "\n",
    "\n",
    "\n",
    "**Patient Population Description for FDA Validation Dataset:**\n",
    "\n",
    "\n",
    "\n",
    "* Patients from all ethnicities from the ages of 0 to 90.\n",
    "\n",
    "* Prior ilnesses of patients should be accounted for.\n",
    "\n",
    "\n",
    "\n",
    "**Ground Truth Acquisition Methodology:**\n",
    "\n",
    "\n",
    "\n",
    "*  At least silver standard or biopsy data is required for the ground truth.\n",
    "\n",
    "\n",
    "\n",
    "**Algorithm Performance Standard:**\n",
    "\n",
    "\n",
    "\n",
    "* According to this [resarch](https://stanfordmlgroup.github.io/projects/chexnet/) with Chexnet.\n",
    "\n",
    "![alt text](results.png \"Chexnet Performance\")\n",
    "\n",
    "\n",
    "\n",
    "* With our algorithm, we should obtain an F1 score of: `0.400000` which is reasonable and very good.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('webapp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e3d694ece4ade7a72832b05ffa056a10eb38dd6b1e73c5d7cb486c654ee2dd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
